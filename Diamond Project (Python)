{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yO7cLjulRlc-"
   },
   "source": [
    "# Linear Regression in Python, \"Sarah Gets a Diamond\" case\n",
    "\n",
    "This notebook provides the code for building several linear models for the \"Sarah Gets a Diamond case\". It containt the following steps:\n",
    "\n",
    "1.   Getting ready: load (install, if needed) the required packages and libraries\n",
    "2.   Data engineering: (i) load the data and \"clean\" it, (ii) create dummy variables ('one-hot encoding') (iii) split the data into training (ID<=6000) and prediction (ID>=6001), (iv) define the vector of depdent variable (Price) and (v) define the matrix of independent variables (all others, excl. ID).\n",
    "3.   Call the functions for linear regression and build (\"train\" or \"fit\" or \"learn\") a model\n",
    "4.   Check the model quality with out-of-sample predictions (\"cross-validation\")\n",
    "5.   Use the trained model to predict the prices (or \"score\") the new diamonds\n",
    "6.   Export the model predictions\n",
    "\n",
    "Recall, however, from the context of the case and from the visualizations that we built (in Tableau) that the question is not only in building a model, but also in choosing between several candidate models (linear, log-transormed, etc.)\n",
    "\n",
    "How to do that? \n",
    "\n",
    "To answer this question we will consider one of the key principles of machine learning, for now applied to regression. This principle -- and this is critical -- works for all models (and even for \"non-models\"). For example, if we build ana analytical process to understand which of two models makes more accurate predictions (for the prices of diamonds, in this case), we can apply this process to compare the model predictions with those of a colleagues, a boss, a \"guru\", etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting Ready\n",
    "\n",
    "This notebook will use certain third-party libraries. They are not installed with Python by default, however, if you install the Anaconda (https://www.anaconda.com/) distribution, then they will be installed together with Python and you can just skip Step 1.1 below.\n",
    "\n",
    "1. Numpy. This is a de-facto standard library for linear algebra in Python, documentation is available by https://numpy.org/doc/\n",
    "2. Pandas. It is most commonly used library for data engineering. Documentation is at https://pandas.pydata.org\n",
    "3. Scikit-Learn. This one contains majority of simple machine-learning algorithms ready to be applied out of box.\n",
    "https://scikit-learn.org/stable/\n",
    "4. Statsmodels. Documentation can be found at https://www.statsmodels.org/stable/index.html.\n",
    "5. Matplotlib. Provides basic plot functionality in Python, https://matplotlib.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zSADsl2MFtO"
   },
   "outputs": [],
   "source": [
    "# Step 1.1: Check conda environment and installed packages and libaries\n",
    "# import sys\n",
    "# !conda env list\n",
    "# !conda list\n",
    "\n",
    "# Installation with Conda Installer:\n",
    "# !conda install pandas # library pandas is included in the numpy package \n",
    "# !conda install scikit-learn\n",
    "# !conda install statsmodels\n",
    "# !conda install matplotlib\n",
    "\n",
    "# alternatively: Installation with Pip Installer:\n",
    "# !pip3 install numpy pandas sklearn statsmodels matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.2:Loading libraries pandas and numpy and giving them short names pd and np. These aliases are industry-standard.\n",
    "# Same for numpy, scikit-learn and statsmodels.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Later we will load other libraries, such as statsmodels, scikit-learn and pyplot\n",
    "# It is somewhat standard to include all of them at the beginning of the code (i.e., here), but for the first time for pedagogical reasons they will appear where necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "owdtmchQMFtT",
    "outputId": "07d65dca-1482-4ee7-d9c8-ef747e0400a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Carat Weight</th>\n",
       "      <th>Cut</th>\n",
       "      <th>Color</th>\n",
       "      <th>Clarity</th>\n",
       "      <th>Polish</th>\n",
       "      <th>Symmetry</th>\n",
       "      <th>Report</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>VG</td>\n",
       "      <td>EX</td>\n",
       "      <td>GIA</td>\n",
       "      <td>5169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.83</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>VS1</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID</td>\n",
       "      <td>AGSL</td>\n",
       "      <td>3470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>EX</td>\n",
       "      <td>EX</td>\n",
       "      <td>GIA</td>\n",
       "      <td>3183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.91</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>VG</td>\n",
       "      <td>VG</td>\n",
       "      <td>GIA</td>\n",
       "      <td>4370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.83</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>SI1</td>\n",
       "      <td>EX</td>\n",
       "      <td>EX</td>\n",
       "      <td>GIA</td>\n",
       "      <td>3171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.53</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID</td>\n",
       "      <td>AGSL</td>\n",
       "      <td>12791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>VG</td>\n",
       "      <td>G</td>\n",
       "      <td>GIA</td>\n",
       "      <td>5747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Fair</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>VG</td>\n",
       "      <td>VG</td>\n",
       "      <td>GIA</td>\n",
       "      <td>10450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2.11</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>VG</td>\n",
       "      <td>VG</td>\n",
       "      <td>GIA</td>\n",
       "      <td>18609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.05</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>VG</td>\n",
       "      <td>G</td>\n",
       "      <td>GIA</td>\n",
       "      <td>7666.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Carat Weight        Cut Color Clarity Polish Symmetry Report    Price\n",
       "0   1          1.10      Ideal     H     SI1     VG       EX    GIA   5169.0\n",
       "1   2          0.83      Ideal     H     VS1     ID       ID   AGSL   3470.0\n",
       "2   3          0.85      Ideal     H     SI1     EX       EX    GIA   3183.0\n",
       "3   4          0.91      Ideal     E     SI1     VG       VG    GIA   4370.0\n",
       "4   5          0.83      Ideal     G     SI1     EX       EX    GIA   3171.0\n",
       "5   6          1.53      Ideal     E     SI1     ID       ID   AGSL  12791.0\n",
       "6   7          1.00  Very Good     D     SI1     VG        G    GIA   5747.0\n",
       "7   8          1.50       Fair     F     SI1     VG       VG    GIA  10450.0\n",
       "8   9          2.11      Ideal     H     SI1     VG       VG    GIA  18609.0\n",
       "9  10          1.05  Very Good     E     VS1     VG        G    GIA   7666.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2.1: Load the data\n",
    "\n",
    "# For local machine -- read the provided CSV datafile into a dataframe and name it ebp_raw_data Note: instead of \"C:\\\\Users\\\\ao37\\\\\" you need to paste the path to where you saved the file\n",
    "Sarah_raw_data = pd.read_csv(\"C:\\\\Users\\\\ao37\\\\0203 CSV data -- Sarah Gets a Diamond data.csv\", sep = ',') \n",
    "\n",
    "# Update the path to guide to where your data is, e.g., Sarah_raw_data = pd.read_csv(\"C:\\\\Users\\\\A.OVCHINNIKOV\\\\0102 CSV data -- Sarah Gets a Diamond data.csv\", sep = ',') \n",
    "\n",
    "# For google collab -- first upload to the cloud, then read it into a dataframe and name it ebp_raw_data\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# import io\n",
    "# Sarah_raw_data = pd.read_csv(io.BytesIO(uploaded['01 CSV data -- Sarah Gets a Diamond.csv']), sep = ',') \n",
    "\n",
    "Sarah_raw_data[0:10] # Display first 10 rows of data (in Python numbering starts with 0, hence these are rows 0 through 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "xbR5US6GMFtX",
    "outputId": "b37f281a-ab69-4194-be95-0d452983ff54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Carat Weight</th>\n",
       "      <th>Price</th>\n",
       "      <th>Cut_Good</th>\n",
       "      <th>Cut_Ideal</th>\n",
       "      <th>Cut_Signature-Ideal</th>\n",
       "      <th>Cut_Very Good</th>\n",
       "      <th>Color_E</th>\n",
       "      <th>Color_F</th>\n",
       "      <th>Color_G</th>\n",
       "      <th>...</th>\n",
       "      <th>Clarity_VS2</th>\n",
       "      <th>Clarity_VVS1</th>\n",
       "      <th>Clarity_VVS2</th>\n",
       "      <th>Polish_G</th>\n",
       "      <th>Polish_ID</th>\n",
       "      <th>Polish_VG</th>\n",
       "      <th>Symmetry_G</th>\n",
       "      <th>Symmetry_ID</th>\n",
       "      <th>Symmetry_VG</th>\n",
       "      <th>Report_GIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5169.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3470.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3183.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.53</td>\n",
       "      <td>12791.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5747.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.50</td>\n",
       "      <td>10450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2.11</td>\n",
       "      <td>18609.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.05</td>\n",
       "      <td>7666.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Carat Weight    Price  Cut_Good  Cut_Ideal  Cut_Signature-Ideal  \\\n",
       "0   1          1.10   5169.0         0          1                    0   \n",
       "1   2          0.83   3470.0         0          1                    0   \n",
       "2   3          0.85   3183.0         0          1                    0   \n",
       "3   4          0.91   4370.0         0          1                    0   \n",
       "4   5          0.83   3171.0         0          1                    0   \n",
       "5   6          1.53  12791.0         0          1                    0   \n",
       "6   7          1.00   5747.0         0          0                    0   \n",
       "7   8          1.50  10450.0         0          0                    0   \n",
       "8   9          2.11  18609.0         0          1                    0   \n",
       "9  10          1.05   7666.0         0          0                    0   \n",
       "\n",
       "   Cut_Very Good  Color_E  Color_F  Color_G  ...  Clarity_VS2  Clarity_VVS1  \\\n",
       "0              0        0        0        0  ...            0             0   \n",
       "1              0        0        0        0  ...            0             0   \n",
       "2              0        0        0        0  ...            0             0   \n",
       "3              0        1        0        0  ...            0             0   \n",
       "4              0        0        0        1  ...            0             0   \n",
       "5              0        1        0        0  ...            0             0   \n",
       "6              1        0        0        0  ...            0             0   \n",
       "7              0        0        1        0  ...            0             0   \n",
       "8              0        0        0        0  ...            0             0   \n",
       "9              1        1        0        0  ...            0             0   \n",
       "\n",
       "   Clarity_VVS2  Polish_G  Polish_ID  Polish_VG  Symmetry_G  Symmetry_ID  \\\n",
       "0             0         0          0          1           0            0   \n",
       "1             0         0          1          0           0            1   \n",
       "2             0         0          0          0           0            0   \n",
       "3             0         0          0          1           0            0   \n",
       "4             0         0          0          0           0            0   \n",
       "5             0         0          1          0           0            1   \n",
       "6             0         0          0          1           1            0   \n",
       "7             0         0          0          1           0            0   \n",
       "8             0         0          0          1           0            0   \n",
       "9             0         0          0          1           1            0   \n",
       "\n",
       "   Symmetry_VG  Report_GIA  \n",
       "0            0           1  \n",
       "1            0           0  \n",
       "2            0           1  \n",
       "3            1           1  \n",
       "4            0           1  \n",
       "5            0           0  \n",
       "6            0           1  \n",
       "7            1           1  \n",
       "8            1           1  \n",
       "9            0           1  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2.2: Creating dummy variables (in machine learning this is called \"one-hot encoding\")\n",
    "Sarah_data = pd.get_dummies(data=Sarah_raw_data, columns = ['Cut', 'Color', 'Clarity', 'Polish', 'Symmetry', 'Report'], drop_first=True) \n",
    "\n",
    "Sarah_data[0:10] # Display first 10 rows of data (rows 0 through 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.3: From the case, the first 6000 rows contain prices and can be used for training. The rest do not and are to be used for predictions\n",
    "\n",
    "Sarah_data_training = Sarah_data[:6000] # Dataframe Sarah_data_training contains the data about the first 6000 diamonds\n",
    "Sarah_data_prediction = Sarah_data[6000:] # Dataframe Sarah_data_prediction contains the data about the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "zzEtPMEZMFtZ",
    "outputId": "9c539ec7-97f0-4a37-cf35-9ee6bab23fd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4370.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price\n",
       "0  5169.0\n",
       "1  3470.0\n",
       "2  3183.0\n",
       "3  4370.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2.4: Define the vector of Y (\"dependent\") variable -- Price; we will build the model to predict Y \n",
    "\n",
    "Y_train = Sarah_data_training[(['Price'])]\n",
    "\n",
    "Y_train[0:4] # Display first 4 values of the Y vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "BeH_2hcQMFtd",
    "outputId": "4043e22c-c387-4f77-cdf7-34595c35f734"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Carat Weight</th>\n",
       "      <th>Cut_Good</th>\n",
       "      <th>Cut_Ideal</th>\n",
       "      <th>Cut_Signature-Ideal</th>\n",
       "      <th>Cut_Very Good</th>\n",
       "      <th>Color_E</th>\n",
       "      <th>Color_F</th>\n",
       "      <th>Color_G</th>\n",
       "      <th>Color_H</th>\n",
       "      <th>Color_I</th>\n",
       "      <th>...</th>\n",
       "      <th>Clarity_VS2</th>\n",
       "      <th>Clarity_VVS1</th>\n",
       "      <th>Clarity_VVS2</th>\n",
       "      <th>Polish_G</th>\n",
       "      <th>Polish_ID</th>\n",
       "      <th>Polish_VG</th>\n",
       "      <th>Symmetry_G</th>\n",
       "      <th>Symmetry_ID</th>\n",
       "      <th>Symmetry_VG</th>\n",
       "      <th>Report_GIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Carat Weight  Cut_Good  Cut_Ideal  Cut_Signature-Ideal  Cut_Very Good  \\\n",
       "0          1.10         0          1                    0              0   \n",
       "1          0.83         0          1                    0              0   \n",
       "2          0.85         0          1                    0              0   \n",
       "3          0.91         0          1                    0              0   \n",
       "\n",
       "   Color_E  Color_F  Color_G  Color_H  Color_I  ...  Clarity_VS2  \\\n",
       "0        0        0        0        1        0  ...            0   \n",
       "1        0        0        0        1        0  ...            0   \n",
       "2        0        0        0        1        0  ...            0   \n",
       "3        1        0        0        0        0  ...            0   \n",
       "\n",
       "   Clarity_VVS1  Clarity_VVS2  Polish_G  Polish_ID  Polish_VG  Symmetry_G  \\\n",
       "0             0             0         0          0          1           0   \n",
       "1             0             0         0          1          0           0   \n",
       "2             0             0         0          0          0           0   \n",
       "3             0             0         0          0          1           0   \n",
       "\n",
       "   Symmetry_ID  Symmetry_VG  Report_GIA  \n",
       "0            0            0           1  \n",
       "1            1            0           0  \n",
       "2            0            0           1  \n",
       "3            0            1           1  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2.5: Define the matrix of X (\"independent\") variables that we will use to predict Y; drop ID and Price as they should not / cannot be used for prediction\n",
    "X_train = Sarah_data_training.drop(['ID','Price'], axis=1) \n",
    "X_train[0:4] # Display first 4 rows of the X matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build (\"train\" or \"fit\") our first linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "colab_type": "code",
    "id": "4JeVrIQSMFtf",
    "outputId": "086c29e1-2725-4dfa-cb21-1446800b9867"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Price</td>      <th>  R-squared:         </th> <td>   0.864</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.863</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1645.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Jan 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:15:28</td>     <th>  Log-Likelihood:    </th> <td> -57908.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6000</td>      <th>  AIC:               </th> <td>1.159e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5976</td>      <th>  BIC:               </th> <td>1.160e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    23</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td> 2.642e+04</td> <td> 1954.801</td> <td>   13.517</td> <td> 0.000</td> <td> 2.26e+04</td> <td> 3.03e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Carat Weight</th>        <td> 1.839e+04</td> <td>  105.110</td> <td>  175.005</td> <td> 0.000</td> <td> 1.82e+04</td> <td> 1.86e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cut_Good</th>            <td> -322.5957</td> <td>  362.520</td> <td>   -0.890</td> <td> 0.374</td> <td>-1033.265</td> <td>  388.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cut_Ideal</th>           <td>  274.6927</td> <td>  355.384</td> <td>    0.773</td> <td> 0.440</td> <td> -421.988</td> <td>  971.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cut_Signature-Ideal</th> <td> 1677.1908</td> <td>  439.716</td> <td>    3.814</td> <td> 0.000</td> <td>  815.189</td> <td> 2539.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cut_Very Good</th>       <td>  -35.6357</td> <td>  345.517</td> <td>   -0.103</td> <td> 0.918</td> <td> -712.973</td> <td>  641.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_E</th>             <td>-2327.3317</td> <td>  200.473</td> <td>  -11.609</td> <td> 0.000</td> <td>-2720.331</td> <td>-1934.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_F</th>             <td>-3078.2407</td> <td>  189.816</td> <td>  -16.217</td> <td> 0.000</td> <td>-3450.349</td> <td>-2706.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_G</th>             <td>-4799.5517</td> <td>  178.263</td> <td>  -26.924</td> <td> 0.000</td> <td>-5149.012</td> <td>-4450.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_H</th>             <td>-6361.2739</td> <td>  188.072</td> <td>  -33.824</td> <td> 0.000</td> <td>-6729.963</td> <td>-5992.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_I</th>             <td>-8039.9918</td> <td>  192.814</td> <td>  -41.698</td> <td> 0.000</td> <td>-8417.977</td> <td>-7662.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_IF</th>          <td>-2.709e+04</td> <td> 1912.086</td> <td>  -14.170</td> <td> 0.000</td> <td>-3.08e+04</td> <td>-2.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_SI1</th>         <td> -3.69e+04</td> <td> 1898.452</td> <td>  -19.436</td> <td> 0.000</td> <td>-4.06e+04</td> <td>-3.32e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_VS1</th>         <td>-3.397e+04</td> <td> 1899.196</td> <td>  -17.887</td> <td> 0.000</td> <td>-3.77e+04</td> <td>-3.02e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_VS2</th>         <td>-3.531e+04</td> <td> 1898.911</td> <td>  -18.596</td> <td> 0.000</td> <td> -3.9e+04</td> <td>-3.16e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_VVS1</th>        <td>-3.058e+04</td> <td> 1909.252</td> <td>  -16.014</td> <td> 0.000</td> <td>-3.43e+04</td> <td>-2.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_VVS2</th>        <td>-3.243e+04</td> <td> 1901.916</td> <td>  -17.053</td> <td> 0.000</td> <td>-3.62e+04</td> <td>-2.87e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Polish_G</th>            <td>    1.4906</td> <td>  201.753</td> <td>    0.007</td> <td> 0.994</td> <td> -394.018</td> <td>  396.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Polish_ID</th>           <td> -584.7362</td> <td>  744.971</td> <td>   -0.785</td> <td> 0.433</td> <td>-2045.148</td> <td>  875.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Polish_VG</th>           <td> -156.7413</td> <td>  126.621</td> <td>   -1.238</td> <td> 0.216</td> <td> -404.964</td> <td>   91.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Symmetry_G</th>          <td> -430.4773</td> <td>  188.917</td> <td>   -2.279</td> <td> 0.023</td> <td> -800.822</td> <td>  -60.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Symmetry_ID</th>         <td>  148.1049</td> <td>  772.420</td> <td>    0.192</td> <td> 0.848</td> <td>-1366.118</td> <td> 1662.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Symmetry_VG</th>         <td> -291.3244</td> <td>  133.555</td> <td>   -2.181</td> <td> 0.029</td> <td> -553.141</td> <td>  -29.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Report_GIA</th>          <td>  184.3296</td> <td>  347.567</td> <td>    0.530</td> <td> 0.596</td> <td> -497.027</td> <td>  865.687</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4389.321</td> <th>  Durbin-Watson:     </th>  <td>   2.040</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>149885.754</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.118</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>26.678</td>  <th>  Cond. No.          </th>  <td>    227.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Price   R-squared:                       0.864\n",
       "Model:                            OLS   Adj. R-squared:                  0.863\n",
       "Method:                 Least Squares   F-statistic:                     1645.\n",
       "Date:                Mon, 11 Jan 2021   Prob (F-statistic):               0.00\n",
       "Time:                        13:15:28   Log-Likelihood:                -57908.\n",
       "No. Observations:                6000   AIC:                         1.159e+05\n",
       "Df Residuals:                    5976   BIC:                         1.160e+05\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                2.642e+04   1954.801     13.517      0.000    2.26e+04    3.03e+04\n",
       "Carat Weight         1.839e+04    105.110    175.005      0.000    1.82e+04    1.86e+04\n",
       "Cut_Good             -322.5957    362.520     -0.890      0.374   -1033.265     388.074\n",
       "Cut_Ideal             274.6927    355.384      0.773      0.440    -421.988     971.373\n",
       "Cut_Signature-Ideal  1677.1908    439.716      3.814      0.000     815.189    2539.193\n",
       "Cut_Very Good         -35.6357    345.517     -0.103      0.918    -712.973     641.702\n",
       "Color_E             -2327.3317    200.473    -11.609      0.000   -2720.331   -1934.332\n",
       "Color_F             -3078.2407    189.816    -16.217      0.000   -3450.349   -2706.132\n",
       "Color_G             -4799.5517    178.263    -26.924      0.000   -5149.012   -4450.092\n",
       "Color_H             -6361.2739    188.072    -33.824      0.000   -6729.963   -5992.584\n",
       "Color_I             -8039.9918    192.814    -41.698      0.000   -8417.977   -7662.006\n",
       "Clarity_IF          -2.709e+04   1912.086    -14.170      0.000   -3.08e+04   -2.33e+04\n",
       "Clarity_SI1          -3.69e+04   1898.452    -19.436      0.000   -4.06e+04   -3.32e+04\n",
       "Clarity_VS1         -3.397e+04   1899.196    -17.887      0.000   -3.77e+04   -3.02e+04\n",
       "Clarity_VS2         -3.531e+04   1898.911    -18.596      0.000    -3.9e+04   -3.16e+04\n",
       "Clarity_VVS1        -3.058e+04   1909.252    -16.014      0.000   -3.43e+04   -2.68e+04\n",
       "Clarity_VVS2        -3.243e+04   1901.916    -17.053      0.000   -3.62e+04   -2.87e+04\n",
       "Polish_G                1.4906    201.753      0.007      0.994    -394.018     396.999\n",
       "Polish_ID            -584.7362    744.971     -0.785      0.433   -2045.148     875.676\n",
       "Polish_VG            -156.7413    126.621     -1.238      0.216    -404.964      91.482\n",
       "Symmetry_G           -430.4773    188.917     -2.279      0.023    -800.822     -60.132\n",
       "Symmetry_ID           148.1049    772.420      0.192      0.848   -1366.118    1662.328\n",
       "Symmetry_VG          -291.3244    133.555     -2.181      0.029    -553.141     -29.508\n",
       "Report_GIA            184.3296    347.567      0.530      0.596    -497.027     865.687\n",
       "==============================================================================\n",
       "Omnibus:                     4389.321   Durbin-Watson:                   2.040\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           149885.754\n",
       "Skew:                           3.118   Prob(JB):                         0.00\n",
       "Kurtosis:                      26.678   Cond. No.                         227.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are several ways to run a linear regressoin in python. \n",
    "\n",
    "# One way is using the statsmodels package\n",
    "# Import the package, give it a short name \"sm\" for ease of use\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train) # In this package, by default, the regression will have no intercept, hence we need to manually add it to the X matrix, and call the result X_sm\n",
    "\n",
    "lm = sm.OLS(Y_train, X_train_sm).fit() # Fit/\"train\"/\"learn\" a linear regression (\"ordinary least squares\", OLS) with vector Y as dependent and matrix X_sm as independent\n",
    "\n",
    "lm.summary() # Display the summary of model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "kSSc09tZMFth",
    "outputId": "67840a70-d161-4a84-891c-198d8475645d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept =  [26423.89481315]\n",
      "Model coefficients =  [[ 1.83948330e+04 -3.22595688e+02  2.74692681e+02  1.67719076e+03\n",
      "  -3.56356533e+01 -2.32733175e+03 -3.07824070e+03 -4.79955175e+03\n",
      "  -6.36127388e+03 -8.03999181e+03 -2.70937885e+04 -3.68981919e+04\n",
      "  -3.39709797e+04 -3.53125448e+04 -3.05753935e+04 -3.24342346e+04\n",
      "   1.49058530e+00 -5.84736225e+02 -1.56741252e+02 -4.30477274e+02\n",
      "   1.48104862e+02 -2.91324371e+02  1.84329597e+02]]\n",
      "R^2 = 0.8635908847404312\n"
     ]
    }
   ],
   "source": [
    "# Another way is using the scikit.learn (sklearn) -- a super-powerful library for machine learning that we will also use later in the course\n",
    "# Import the linear regression package from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression().fit(X_train, Y_train) # Fit/\"train\"/\"learn\" a linear regression with vector Y as dependent and matrix X as independent\n",
    "\n",
    "print(\"Intercept = \",lm.intercept_) # Print the resultant/estimated/\"learned\" model intercept \n",
    "\n",
    "print(\"Model coefficients = \", lm.coef_) # Print the resultant/estimated/\"learned\" model coefficients (in order of variables in X)\n",
    "\n",
    "print(\"R^2 =\",lm.score(X_train,Y_train)) # Print the resultant/estimated/\"learned\" model R-squared\n",
    "\n",
    "# Note: there is no easy way to obtain other model outputs (p-values, etc.) from sklearn, as these outputs are not present in other, non-regression, machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So, our first (linear) model has been built\n",
    "\n",
    "It gives us a formula into which we substitute the characteristics of the a diamond to obtain the prediction of its price: Price = 26423 + 18394 * Carat Weight - 322 if Cut is Good + 274 if Cut is Ideal + ... \n",
    "\n",
    "However, how good is this model? How to check that? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Cross-validation\n",
    "\n",
    "The main machine learning principle that allows to answer this question -- cross-validation: splitting the data into training and testing subsets, training on the former and testing on the latter. Below (since this is our first time doing this) we will split (\"fold\") once and just by ID. Commonly, 5-10 folds are used with stratified random splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Carat Weight</th>\n",
       "      <th>Price</th>\n",
       "      <th>Cut_Good</th>\n",
       "      <th>Cut_Ideal</th>\n",
       "      <th>Cut_Signature-Ideal</th>\n",
       "      <th>Cut_Very Good</th>\n",
       "      <th>Color_E</th>\n",
       "      <th>Color_F</th>\n",
       "      <th>Color_G</th>\n",
       "      <th>...</th>\n",
       "      <th>Clarity_VS2</th>\n",
       "      <th>Clarity_VVS1</th>\n",
       "      <th>Clarity_VVS2</th>\n",
       "      <th>Polish_G</th>\n",
       "      <th>Polish_ID</th>\n",
       "      <th>Polish_VG</th>\n",
       "      <th>Symmetry_G</th>\n",
       "      <th>Symmetry_ID</th>\n",
       "      <th>Symmetry_VG</th>\n",
       "      <th>Report_GIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5169.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3470.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3183.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Carat Weight   Price  Cut_Good  Cut_Ideal  Cut_Signature-Ideal  \\\n",
       "0   1          1.10  5169.0         0          1                    0   \n",
       "1   2          0.83  3470.0         0          1                    0   \n",
       "2   3          0.85  3183.0         0          1                    0   \n",
       "3   4          0.91  4370.0         0          1                    0   \n",
       "\n",
       "   Cut_Very Good  Color_E  Color_F  Color_G  ...  Clarity_VS2  Clarity_VVS1  \\\n",
       "0              0        0        0        0  ...            0             0   \n",
       "1              0        0        0        0  ...            0             0   \n",
       "2              0        0        0        0  ...            0             0   \n",
       "3              0        1        0        0  ...            0             0   \n",
       "\n",
       "   Clarity_VVS2  Polish_G  Polish_ID  Polish_VG  Symmetry_G  Symmetry_ID  \\\n",
       "0             0         0          0          1           0            0   \n",
       "1             0         0          1          0           0            1   \n",
       "2             0         0          0          0           0            0   \n",
       "3             0         0          0          1           0            0   \n",
       "\n",
       "   Symmetry_VG  Report_GIA  \n",
       "0            0           1  \n",
       "1            0           0  \n",
       "2            0           1  \n",
       "3            1           1  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefine the training data. Instead of 6000, out the first 5000 diamonds into a training \n",
    "train = Sarah_data.iloc[:5000] \n",
    "\n",
    "train[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Carat Weight</th>\n",
       "      <th>Price</th>\n",
       "      <th>Cut_Good</th>\n",
       "      <th>Cut_Ideal</th>\n",
       "      <th>Cut_Signature-Ideal</th>\n",
       "      <th>Cut_Very Good</th>\n",
       "      <th>Color_E</th>\n",
       "      <th>Color_F</th>\n",
       "      <th>Color_G</th>\n",
       "      <th>...</th>\n",
       "      <th>Clarity_VS2</th>\n",
       "      <th>Clarity_VVS1</th>\n",
       "      <th>Clarity_VVS2</th>\n",
       "      <th>Polish_G</th>\n",
       "      <th>Polish_ID</th>\n",
       "      <th>Polish_VG</th>\n",
       "      <th>Symmetry_G</th>\n",
       "      <th>Symmetry_ID</th>\n",
       "      <th>Symmetry_VG</th>\n",
       "      <th>Report_GIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>5001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8151.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>5002</td>\n",
       "      <td>1.02</td>\n",
       "      <td>6704.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>5003</td>\n",
       "      <td>1.50</td>\n",
       "      <td>13603.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>5004</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4466.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Carat Weight    Price  Cut_Good  Cut_Ideal  Cut_Signature-Ideal  \\\n",
       "5000  5001          1.00   8151.0         0          1                    0   \n",
       "5001  5002          1.02   6704.0         0          1                    0   \n",
       "5002  5003          1.50  13603.0         1          0                    0   \n",
       "5003  5004          0.91   4466.0         0          0                    0   \n",
       "\n",
       "      Cut_Very Good  Color_E  Color_F  Color_G  ...  Clarity_VS2  \\\n",
       "5000              0        0        0        1  ...            0   \n",
       "5001              0        1        0        0  ...            1   \n",
       "5002              0        0        0        0  ...            0   \n",
       "5003              1        0        0        0  ...            0   \n",
       "\n",
       "      Clarity_VVS1  Clarity_VVS2  Polish_G  Polish_ID  Polish_VG  Symmetry_G  \\\n",
       "5000             0             1         0          0          0           0   \n",
       "5001             0             0         0          0          1           1   \n",
       "5002             0             0         0          0          0           0   \n",
       "5003             0             0         0          0          1           0   \n",
       "\n",
       "      Symmetry_ID  Symmetry_VG  Report_GIA  \n",
       "5000            0            0           1  \n",
       "5001            0            0           1  \n",
       "5002            0            0           1  \n",
       "5003            0            1           1  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Sarah_data.iloc[5000:6000] # Define the testing data: i,e., ID 5001-6000\n",
    "\n",
    "test[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>8151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>6704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>13603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>4466.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Price\n",
       "5000   8151.0\n",
       "5001   6704.0\n",
       "5002  13603.0\n",
       "5003   4466.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefine X and Y for the training and testing data\n",
    "\n",
    "Y_train = train[(['Price'])]\n",
    "X_train = train.drop(['ID', 'Price'], axis = 1)\n",
    "\n",
    "# IMPORTANT -- the vector Y_test contains the actual prices of diamonds in the testing set; we will compare our model predictions to them to calculate the error metric\n",
    "\n",
    "Y_test = test[(['Price'])]\n",
    "X_test = test.drop(['ID', 'Price'], axis = 1)\n",
    "\n",
    "Y_test[0:4] # Actual prices for diamonds in the testing set (8151 dollars, 6704 dollars, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8042.42186849],\n",
       "       [ 7426.03576672],\n",
       "       [16717.56158277],\n",
       "       [ 5971.23447045]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit/\"train\"/\"learn\" a linear regression on the training data\n",
    "lm = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "# Use the trained model to predict the prices for the testing data. Call the vector of predicted prices Y_pred\n",
    "Y_pred = lm.predict(X_test)\n",
    "\n",
    "Y_pred[0:4] # Display the predicted price for the first 4 diamonds in the testing data (8042 dollars, 7426 dollars, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>1.332084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>10.770223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>22.896137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>33.704310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Price\n",
       "5000   1.332084\n",
       "5001  10.770223\n",
       "5002  22.896137\n",
       "5003  33.704310"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, calculate the metric for the model quality. As we discussed in class, there are many possible metrics, one of them is MAPE (mean absolute percentage error) https://en.wikipedia.org/wiki/Mean_absolute_percentage_error  \n",
    "\n",
    "percent_errors = np.abs((Y_test - Y_pred) / Y_test) *100\n",
    "\n",
    "percent_errors[0:4] # Display first 4 percentage errors (8151-8042)/8151 = 1.33%, (7426-6704)/6704 = 10.77%, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model MAPE =  Price    27.690718\n",
      "dtype: float64 %\n"
     ]
    }
   ],
   "source": [
    "# Display MAPE \n",
    "\n",
    "print(\"Linear Model MAPE = \", np.mean(percent_errors), \"%\")\n",
    "\n",
    "# plt.scatter(test['Price'], test_predictions ,  color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our current model has an out-of-sample MAPE ~ 27% \n",
    "\n",
    "___________________________________________________________________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat Steps 3 and 4 for the log-log model from the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp, log\n",
    "\n",
    "# apply log transforms\n",
    "Sarah_data['Price'] = Sarah_data['Price'].transform(log)\n",
    "Sarah_data['Carat Weight'] = Sarah_data['Carat Weight'].transform(log)\n",
    "\n",
    "Sarah_data_training = Sarah_data[:6000] # Dataframe Sarah_data_training contains the data about the first 6000 diamonds\n",
    "Sarah_data_prediction = Sarah_data[6000:] # Dataframe Sarah_data_prediction contains the data about the rest\n",
    "\n",
    "# IMPORTANT: the above code changed the dataframe Sarah_data: instead of the prices in dollars, the data now contains their logarithms. Same for Carat Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.550435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.151910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.065579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.382518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Price\n",
       "0  8.550435\n",
       "1  8.151910\n",
       "2  8.065579\n",
       "3  8.382518"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = Sarah_data_training[(['Price'])] \n",
    "Y_train[0:4] # Observe, the \"Y\" variable for the first diamond in the training data is 8.550435, not 5169 -- why? That is the logarithm. Indeed, exp(8.55043) = 5160 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Carat Weight</th>\n",
       "      <th>Cut_Good</th>\n",
       "      <th>Cut_Ideal</th>\n",
       "      <th>Cut_Signature-Ideal</th>\n",
       "      <th>Cut_Very Good</th>\n",
       "      <th>Color_E</th>\n",
       "      <th>Color_F</th>\n",
       "      <th>Color_G</th>\n",
       "      <th>Color_H</th>\n",
       "      <th>Color_I</th>\n",
       "      <th>...</th>\n",
       "      <th>Clarity_VS2</th>\n",
       "      <th>Clarity_VVS1</th>\n",
       "      <th>Clarity_VVS2</th>\n",
       "      <th>Polish_G</th>\n",
       "      <th>Polish_ID</th>\n",
       "      <th>Polish_VG</th>\n",
       "      <th>Symmetry_G</th>\n",
       "      <th>Symmetry_ID</th>\n",
       "      <th>Symmetry_VG</th>\n",
       "      <th>Report_GIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095310</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.186330</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.162519</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.094311</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Carat Weight  Cut_Good  Cut_Ideal  Cut_Signature-Ideal  Cut_Very Good  \\\n",
       "0      0.095310         0          1                    0              0   \n",
       "1     -0.186330         0          1                    0              0   \n",
       "2     -0.162519         0          1                    0              0   \n",
       "3     -0.094311         0          1                    0              0   \n",
       "\n",
       "   Color_E  Color_F  Color_G  Color_H  Color_I  ...  Clarity_VS2  \\\n",
       "0        0        0        0        1        0  ...            0   \n",
       "1        0        0        0        1        0  ...            0   \n",
       "2        0        0        0        1        0  ...            0   \n",
       "3        1        0        0        0        0  ...            0   \n",
       "\n",
       "   Clarity_VVS1  Clarity_VVS2  Polish_G  Polish_ID  Polish_VG  Symmetry_G  \\\n",
       "0             0             0         0          0          1           0   \n",
       "1             0             0         0          1          0           0   \n",
       "2             0             0         0          0          0           0   \n",
       "3             0             0         0          0          1           0   \n",
       "\n",
       "   Symmetry_ID  Symmetry_VG  Report_GIA  \n",
       "0            0            0           1  \n",
       "1            1            0           0  \n",
       "2            0            0           1  \n",
       "3            0            1           1  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = Sarah_data_training.drop(['ID','Price'], axis=1) \n",
    "X_train[0:4] # Same for the Carat Weight: 0.095311, and not 1.10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Price</td>      <th>  R-squared:         </th>  <td>   0.980</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.980</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.260e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Jan 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:15:29</td>     <th>  Log-Likelihood:    </th>  <td>  5244.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6000</td>      <th>  AIC:               </th> <td>-1.044e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5976</td>      <th>  BIC:               </th> <td>-1.028e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    23</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>    9.4461</td> <td>    0.052</td> <td>  180.732</td> <td> 0.000</td> <td>    9.344</td> <td>    9.549</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Carat Weight</th>        <td>    1.9874</td> <td>    0.004</td> <td>  490.292</td> <td> 0.000</td> <td>    1.979</td> <td>    1.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cut_Good</th>            <td>    0.0502</td> <td>    0.010</td> <td>    5.156</td> <td> 0.000</td> <td>    0.031</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cut_Ideal</th>           <td>    0.1061</td> <td>    0.010</td> <td>   11.125</td> <td> 0.000</td> <td>    0.087</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cut_Signature-Ideal</th> <td>    0.2518</td> <td>    0.012</td> <td>   21.332</td> <td> 0.000</td> <td>    0.229</td> <td>    0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cut_Very Good</th>       <td>    0.0782</td> <td>    0.009</td> <td>    8.428</td> <td> 0.000</td> <td>    0.060</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_E</th>             <td>   -0.0858</td> <td>    0.005</td> <td>  -15.951</td> <td> 0.000</td> <td>   -0.096</td> <td>   -0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_F</th>             <td>   -0.1232</td> <td>    0.005</td> <td>  -24.181</td> <td> 0.000</td> <td>   -0.133</td> <td>   -0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_G</th>             <td>   -0.2192</td> <td>    0.005</td> <td>  -45.787</td> <td> 0.000</td> <td>   -0.229</td> <td>   -0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_H</th>             <td>   -0.3495</td> <td>    0.005</td> <td>  -69.199</td> <td> 0.000</td> <td>   -0.359</td> <td>   -0.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_I</th>             <td>   -0.4944</td> <td>    0.005</td> <td>  -95.443</td> <td> 0.000</td> <td>   -0.505</td> <td>   -0.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_IF</th>          <td>   -0.3002</td> <td>    0.051</td> <td>   -5.849</td> <td> 0.000</td> <td>   -0.401</td> <td>   -0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_SI1</th>         <td>   -0.8636</td> <td>    0.051</td> <td>  -16.949</td> <td> 0.000</td> <td>   -0.964</td> <td>   -0.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_VS1</th>         <td>   -0.6221</td> <td>    0.051</td> <td>  -12.204</td> <td> 0.000</td> <td>   -0.722</td> <td>   -0.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_VS2</th>         <td>   -0.7016</td> <td>    0.051</td> <td>  -13.765</td> <td> 0.000</td> <td>   -0.801</td> <td>   -0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_VVS1</th>        <td>   -0.4206</td> <td>    0.051</td> <td>   -8.208</td> <td> 0.000</td> <td>   -0.521</td> <td>   -0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_VVS2</th>        <td>   -0.4932</td> <td>    0.051</td> <td>   -9.663</td> <td> 0.000</td> <td>   -0.593</td> <td>   -0.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Polish_G</th>            <td>   -0.0368</td> <td>    0.005</td> <td>   -6.796</td> <td> 0.000</td> <td>   -0.047</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Polish_ID</th>           <td>    0.0239</td> <td>    0.020</td> <td>    1.196</td> <td> 0.232</td> <td>   -0.015</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Polish_VG</th>           <td>   -0.0222</td> <td>    0.003</td> <td>   -6.529</td> <td> 0.000</td> <td>   -0.029</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Symmetry_G</th>          <td>   -0.0215</td> <td>    0.005</td> <td>   -4.238</td> <td> 0.000</td> <td>   -0.031</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Symmetry_ID</th>         <td> 7.571e-05</td> <td>    0.021</td> <td>    0.004</td> <td> 0.997</td> <td>   -0.041</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Symmetry_VG</th>         <td>   -0.0201</td> <td>    0.004</td> <td>   -5.608</td> <td> 0.000</td> <td>   -0.027</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Report_GIA</th>          <td>    0.0493</td> <td>    0.009</td> <td>    5.284</td> <td> 0.000</td> <td>    0.031</td> <td>    0.068</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>262.841</td> <th>  Durbin-Watson:     </th> <td>   1.998</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 683.775</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.220</td>  <th>  Prob(JB):          </th> <td>3.31e-149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.594</td>  <th>  Cond. No.          </th> <td>    180.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Price   R-squared:                       0.980\n",
       "Model:                            OLS   Adj. R-squared:                  0.980\n",
       "Method:                 Least Squares   F-statistic:                 1.260e+04\n",
       "Date:                Mon, 11 Jan 2021   Prob (F-statistic):               0.00\n",
       "Time:                        13:15:29   Log-Likelihood:                 5244.9\n",
       "No. Observations:                6000   AIC:                        -1.044e+04\n",
       "Df Residuals:                    5976   BIC:                        -1.028e+04\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                   9.4461      0.052    180.732      0.000       9.344       9.549\n",
       "Carat Weight            1.9874      0.004    490.292      0.000       1.979       1.995\n",
       "Cut_Good                0.0502      0.010      5.156      0.000       0.031       0.069\n",
       "Cut_Ideal               0.1061      0.010     11.125      0.000       0.087       0.125\n",
       "Cut_Signature-Ideal     0.2518      0.012     21.332      0.000       0.229       0.275\n",
       "Cut_Very Good           0.0782      0.009      8.428      0.000       0.060       0.096\n",
       "Color_E                -0.0858      0.005    -15.951      0.000      -0.096      -0.075\n",
       "Color_F                -0.1232      0.005    -24.181      0.000      -0.133      -0.113\n",
       "Color_G                -0.2192      0.005    -45.787      0.000      -0.229      -0.210\n",
       "Color_H                -0.3495      0.005    -69.199      0.000      -0.359      -0.340\n",
       "Color_I                -0.4944      0.005    -95.443      0.000      -0.505      -0.484\n",
       "Clarity_IF             -0.3002      0.051     -5.849      0.000      -0.401      -0.200\n",
       "Clarity_SI1            -0.8636      0.051    -16.949      0.000      -0.964      -0.764\n",
       "Clarity_VS1            -0.6221      0.051    -12.204      0.000      -0.722      -0.522\n",
       "Clarity_VS2            -0.7016      0.051    -13.765      0.000      -0.801      -0.602\n",
       "Clarity_VVS1           -0.4206      0.051     -8.208      0.000      -0.521      -0.320\n",
       "Clarity_VVS2           -0.4932      0.051     -9.663      0.000      -0.593      -0.393\n",
       "Polish_G               -0.0368      0.005     -6.796      0.000      -0.047      -0.026\n",
       "Polish_ID               0.0239      0.020      1.196      0.232      -0.015       0.063\n",
       "Polish_VG              -0.0222      0.003     -6.529      0.000      -0.029      -0.016\n",
       "Symmetry_G             -0.0215      0.005     -4.238      0.000      -0.031      -0.012\n",
       "Symmetry_ID          7.571e-05      0.021      0.004      0.997      -0.041       0.041\n",
       "Symmetry_VG            -0.0201      0.004     -5.608      0.000      -0.027      -0.013\n",
       "Report_GIA              0.0493      0.009      5.284      0.000       0.031       0.068\n",
       "==============================================================================\n",
       "Omnibus:                      262.841   Durbin-Watson:                   1.998\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              683.775\n",
       "Skew:                           0.220   Prob(JB):                    3.31e-149\n",
       "Kurtosis:                       4.594   Cond. No.                         180.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train) \n",
    "\n",
    "\n",
    "lm = sm.OLS(Y_train, X_train_sm).fit() \n",
    "lm.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "kSSc09tZMFth",
    "outputId": "67840a70-d161-4a84-891c-198d8475645d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept =  [9.44611099]\n",
      "Model coefficients =  [[ 1.98738805e+00  5.01803703e-02  1.06133351e-01  2.51799679e-01\n",
      "   7.81708053e-02 -8.58346642e-02 -1.23215948e-01 -2.19169040e-01\n",
      "  -3.49474631e-01 -4.94358267e-01 -3.00187770e-01 -8.63635300e-01\n",
      "  -6.22106232e-01 -7.01559703e-01 -4.20633848e-01 -4.93243211e-01\n",
      "  -3.68065460e-02  2.39145883e-02 -2.21901183e-02 -2.14927133e-02\n",
      "   7.57136732e-05 -2.01005934e-02  4.92991686e-02]]\n",
      "R^2 = 0.979801588042999\n"
     ]
    }
   ],
   "source": [
    "# Just for practice, repeat the same with sklearn:\n",
    "\n",
    "lm = LinearRegression().fit(X_train, Y_train) # Fit/\"train\"/\"learn\" a linear regression with vector Y as dependent and matrix X as independent\n",
    "\n",
    "print(\"Intercept = \",lm.intercept_) # Print the resultant/estimated/\"learned\" model intercept \n",
    "\n",
    "print(\"Model coefficients = \", lm.coef_) # Print the resultant/estimated/\"learned\" model coefficients (in order of variables in X)\n",
    "\n",
    "print(\"R^2 =\",lm.score(X_train,Y_train)) # Print the resultant/estimated/\"learned\" model R-squared\n",
    "\n",
    "# Note: there is no easy way to obtain other model outputs (p-values, etc.) from sklearn, as these outputs are not present in other, non-regression, machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So, our second (log-log) model has been built\n",
    "\n",
    "It gives us a different formula into which we substitute the characteristics of the a diamond to obtain the prediction of its price: Log of Price = 9.44 + 1.987 * Log of Carat Weight +0.00501 if Cut is Good + 0.1061 if Cut is Ideal + ... - 0.0858 if Color is E ... - 0.4944 if Color is I ...\n",
    "\n",
    "However, how good is this model? Lets repeat the same \"trick\" with the testing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Log Model MAPE =  Price    7.812152\n",
      "dtype: float64 %\n"
     ]
    }
   ],
   "source": [
    "train = Sarah_data.iloc[:5000]\n",
    "test = Sarah_data.iloc[5000:6000]\n",
    "\n",
    "Y_train = train[(['Price'])]\n",
    "X_train = train.drop(['ID', 'Price'], axis = 1)\n",
    "\n",
    "Y_test = np.exp(test[(['Price'])])\n",
    "X_test = test.drop(['ID', 'Price'], axis = 1)\n",
    "\n",
    "lm = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_log = np.exp(lm.predict(X_test)) # Two nuances here: (i) the model predicts Log of Price, hence we need to take exp(); (ii) we gave the vector of predicted prices a different name -- Y_pred_log\n",
    "\n",
    "percent_errors = np.abs((Y_test - Y_pred_log) / Y_test) *100\n",
    "\n",
    "percent_errors[0:4]\n",
    "\n",
    "print(\"Log-Log Model MAPE = \", np.mean(percent_errors), \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UpenKQREWc07"
   },
   "source": [
    "#  WOW -- the log-log model has out-of-sample MAPE of ~ 7.8% \n",
    "\n",
    "Which of the two models will you choose? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the models' predictions visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import a plotting package, and give it a short name plt\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.scatter(Y_test, Y_pred, color='blue') # actual vs predicted prices for the linear model \n",
    "plt.ylabel('Preeicted price, Linear model') # vertical axis title\n",
    "plt.xlabel('Actual price') # horizontal axis title\n",
    "plt.plot([0, 70000], [0, 70000], color='black', lw=2) # 45-degree line (at which error = 0)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same for the log-log model:\n",
    "\n",
    "plt.scatter(Y_test, Y_pred_log, color='red')\n",
    "plt.ylabel('Preeicted price, Log-Log model')\n",
    "plt.xlabel('Actual price')\n",
    "plt.plot([0, 70000], [0, 70000], color='black', lw=2)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to see that the predictions on the second graph are a lot closer to the 45-degree line. the first plot also has negative predicted prices(!). This once again supports that the log-log model is better. \n",
    "\n",
    "\n",
    "# How to improve the model further?\n",
    "\n",
    "Recall our Tableau visualizations: we observed four effects:\n",
    "\n",
    "1.   Price increases with Carat Weight -- our model already \"learned\" that -- Carat Weight is one of the variables, and its coefficient is positive\n",
    "2.   Price increases exponentially with Carat Weight -- our model already \"learned\" that with log-log transofrmation. A side note: an equivalent observation is that the dispersion of Prices increases in Carat Weight\n",
    "3.   Diamonds with \"better\" colors are more expensive -- our model already \"learned\" that too: the best (\"D\") color diamond is in the intercept, and the other Color coefficients are negative \n",
    "4.   Price increases faster in Carat Weight for the diamonds of \"better\" colors -- our model has not learned that jet as there is only one coefficient for Carat Weight that does not change with Color ... \n",
    "\n",
    "How to do this? We need to generate new variables (\"engineer new features\") that would help our model learn that. Such variables (\"features\") are called \"interactions\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Carat Weight</th>\n",
       "      <th>Price</th>\n",
       "      <th>Cut_Good</th>\n",
       "      <th>Cut_Ideal</th>\n",
       "      <th>Cut_Signature-Ideal</th>\n",
       "      <th>Cut_Very Good</th>\n",
       "      <th>Color_E</th>\n",
       "      <th>Color_F</th>\n",
       "      <th>Color_G</th>\n",
       "      <th>...</th>\n",
       "      <th>Polish_VG</th>\n",
       "      <th>Symmetry_G</th>\n",
       "      <th>Symmetry_ID</th>\n",
       "      <th>Symmetry_VG</th>\n",
       "      <th>Report_GIA</th>\n",
       "      <th>Carat Weight:Color_E</th>\n",
       "      <th>Carat Weight:Color_F</th>\n",
       "      <th>Carat Weight:Color_G</th>\n",
       "      <th>Carat Weight:Color_H</th>\n",
       "      <th>Carat Weight:Color_I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.095310</td>\n",
       "      <td>8.550435</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.095310</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.186330</td>\n",
       "      <td>8.151910</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.186330</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>8.065579</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.094311</td>\n",
       "      <td>8.382518</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.094311</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.186330</td>\n",
       "      <td>8.061802</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.18633</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.425268</td>\n",
       "      <td>9.456497</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.425268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.656433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>9.254357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.746688</td>\n",
       "      <td>9.831401</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.746688</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.048790</td>\n",
       "      <td>8.944550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Carat Weight     Price  Cut_Good  Cut_Ideal  Cut_Signature-Ideal  \\\n",
       "0   1      0.095310  8.550435         0          1                    0   \n",
       "1   2     -0.186330  8.151910         0          1                    0   \n",
       "2   3     -0.162519  8.065579         0          1                    0   \n",
       "3   4     -0.094311  8.382518         0          1                    0   \n",
       "4   5     -0.186330  8.061802         0          1                    0   \n",
       "5   6      0.425268  9.456497         0          1                    0   \n",
       "6   7      0.000000  8.656433         0          0                    0   \n",
       "7   8      0.405465  9.254357         0          0                    0   \n",
       "8   9      0.746688  9.831401         0          1                    0   \n",
       "9  10      0.048790  8.944550         0          0                    0   \n",
       "\n",
       "   Cut_Very Good  Color_E  Color_F  Color_G  ...  Polish_VG  Symmetry_G  \\\n",
       "0              0        0        0        0  ...          1           0   \n",
       "1              0        0        0        0  ...          0           0   \n",
       "2              0        0        0        0  ...          0           0   \n",
       "3              0        1        0        0  ...          1           0   \n",
       "4              0        0        0        1  ...          0           0   \n",
       "5              0        1        0        0  ...          0           0   \n",
       "6              1        0        0        0  ...          1           1   \n",
       "7              0        0        1        0  ...          1           0   \n",
       "8              0        0        0        0  ...          1           0   \n",
       "9              1        1        0        0  ...          1           1   \n",
       "\n",
       "   Symmetry_ID  Symmetry_VG  Report_GIA  Carat Weight:Color_E  \\\n",
       "0            0            0           1              0.000000   \n",
       "1            1            0           0             -0.000000   \n",
       "2            0            0           1             -0.000000   \n",
       "3            0            1           1             -0.094311   \n",
       "4            0            0           1             -0.000000   \n",
       "5            1            0           0              0.425268   \n",
       "6            0            0           1              0.000000   \n",
       "7            0            1           1              0.000000   \n",
       "8            0            1           1              0.000000   \n",
       "9            0            0           1              0.048790   \n",
       "\n",
       "   Carat Weight:Color_F  Carat Weight:Color_G  Carat Weight:Color_H  \\\n",
       "0              0.000000               0.00000              0.095310   \n",
       "1             -0.000000              -0.00000             -0.186330   \n",
       "2             -0.000000              -0.00000             -0.162519   \n",
       "3             -0.000000              -0.00000             -0.000000   \n",
       "4             -0.000000              -0.18633             -0.000000   \n",
       "5              0.000000               0.00000              0.000000   \n",
       "6              0.000000               0.00000              0.000000   \n",
       "7              0.405465               0.00000              0.000000   \n",
       "8              0.000000               0.00000              0.746688   \n",
       "9              0.000000               0.00000              0.000000   \n",
       "\n",
       "   Carat Weight:Color_I  \n",
       "0                   0.0  \n",
       "1                  -0.0  \n",
       "2                  -0.0  \n",
       "3                  -0.0  \n",
       "4                  -0.0  \n",
       "5                   0.0  \n",
       "6                   0.0  \n",
       "7                   0.0  \n",
       "8                   0.0  \n",
       "9                   0.0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The simplest form of interaction is just multiplying the variables one by another https://en.wikipedia.org/wiki/Interaction_(statistics)\n",
    "\n",
    "Sarah_data['Carat Weight:Color_E'] = Sarah_data['Carat Weight'] * Sarah_data['Color_E']\n",
    "Sarah_data['Carat Weight:Color_F'] = Sarah_data['Carat Weight'] * Sarah_data['Color_F']\n",
    "Sarah_data['Carat Weight:Color_G'] = Sarah_data['Carat Weight'] * Sarah_data['Color_G']\n",
    "Sarah_data['Carat Weight:Color_H'] = Sarah_data['Carat Weight'] * Sarah_data['Color_H']\n",
    "Sarah_data['Carat Weight:Color_I'] = Sarah_data['Carat Weight'] * Sarah_data['Color_I']\n",
    "\n",
    "Sarah_data[0:10] # Check how these variables look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Log Model with Interactions MAPE =  Price    7.503237\n",
      "dtype: float64 %\n"
     ]
    }
   ],
   "source": [
    "# How much better wil the model become? Repeat the \"trick\" with training and testing\n",
    "\n",
    "train = Sarah_data.iloc[:5000]\n",
    "test = Sarah_data.iloc[5000:6000]\n",
    "\n",
    "Y_train = train[(['Price'])]\n",
    "X_train = train.drop(['ID', 'Price'], axis = 1)\n",
    "\n",
    "Y_test = np.exp(test[(['Price'])])\n",
    "X_test = test.drop(['ID', 'Price'], axis = 1)\n",
    "\n",
    "lm = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_log = np.exp(lm.predict(X_test)) \n",
    "\n",
    "percent_errors = np.abs((Y_test - Y_pred_log) / Y_test) *100\n",
    "\n",
    "percent_errors[0:4]\n",
    "\n",
    "print(\"Log-Log Model with Interactions MAPE = \", np.mean(percent_errors), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UpenKQREWc07"
   },
   "source": [
    "#  Nice! The MAPE reduced further to ~ 7.5% \n",
    "\n",
    "Which of the two models will you choose? \n",
    "\n",
    "What else can we do to further improve the model? Continue feature engineering -- interactions with other variables, higher-degree interactions (e.g., Carat Weight * Color * Cut), aggregating/clustering variables (e.g., Carat Weight > 2), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Price</td>      <th>  R-squared:         </th> <td>   0.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9484.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Jan 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:15:31</td>     <th>  Log-Likelihood:    </th> <td>  4623.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>  -9189.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4971</td>      <th>  BIC:               </th> <td>  -9000.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    28</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    9.3536</td> <td>    0.051</td> <td>  184.793</td> <td> 0.000</td> <td>    9.254</td> <td>    9.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Carat Weight</th>         <td>    2.1472</td> <td>    0.013</td> <td>  171.045</td> <td> 0.000</td> <td>    2.123</td> <td>    2.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cut_Good</th>             <td>    0.0490</td> <td>    0.010</td> <td>    4.817</td> <td> 0.000</td> <td>    0.029</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cut_Ideal</th>            <td>    0.1059</td> <td>    0.010</td> <td>   10.596</td> <td> 0.000</td> <td>    0.086</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cut_Signature-Ideal</th>  <td>    0.2494</td> <td>    0.012</td> <td>   20.227</td> <td> 0.000</td> <td>    0.225</td> <td>    0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cut_Very Good</th>        <td>    0.0773</td> <td>    0.010</td> <td>    7.960</td> <td> 0.000</td> <td>    0.058</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_E</th>              <td>   -0.0667</td> <td>    0.006</td> <td>  -10.752</td> <td> 0.000</td> <td>   -0.079</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_F</th>              <td>   -0.1097</td> <td>    0.006</td> <td>  -18.104</td> <td> 0.000</td> <td>   -0.122</td> <td>   -0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_G</th>              <td>   -0.1963</td> <td>    0.006</td> <td>  -34.026</td> <td> 0.000</td> <td>   -0.208</td> <td>   -0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_H</th>              <td>   -0.2953</td> <td>    0.006</td> <td>  -48.130</td> <td> 0.000</td> <td>   -0.307</td> <td>   -0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Color_I</th>              <td>   -0.4314</td> <td>    0.006</td> <td>  -67.161</td> <td> 0.000</td> <td>   -0.444</td> <td>   -0.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_IF</th>           <td>   -0.2296</td> <td>    0.049</td> <td>   -4.660</td> <td> 0.000</td> <td>   -0.326</td> <td>   -0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_SI1</th>          <td>   -0.7838</td> <td>    0.049</td> <td>  -16.023</td> <td> 0.000</td> <td>   -0.880</td> <td>   -0.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_VS1</th>          <td>   -0.5443</td> <td>    0.049</td> <td>  -11.125</td> <td> 0.000</td> <td>   -0.640</td> <td>   -0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_VS2</th>          <td>   -0.6233</td> <td>    0.049</td> <td>  -12.741</td> <td> 0.000</td> <td>   -0.719</td> <td>   -0.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_VVS1</th>         <td>   -0.3454</td> <td>    0.049</td> <td>   -7.022</td> <td> 0.000</td> <td>   -0.442</td> <td>   -0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clarity_VVS2</th>         <td>   -0.4178</td> <td>    0.049</td> <td>   -8.529</td> <td> 0.000</td> <td>   -0.514</td> <td>   -0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Polish_G</th>             <td>   -0.0371</td> <td>    0.006</td> <td>   -6.608</td> <td> 0.000</td> <td>   -0.048</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Polish_ID</th>            <td>    0.0305</td> <td>    0.022</td> <td>    1.380</td> <td> 0.168</td> <td>   -0.013</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Polish_VG</th>            <td>   -0.0225</td> <td>    0.004</td> <td>   -6.357</td> <td> 0.000</td> <td>   -0.029</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Symmetry_G</th>           <td>   -0.0242</td> <td>    0.005</td> <td>   -4.603</td> <td> 0.000</td> <td>   -0.035</td> <td>   -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Symmetry_ID</th>          <td>   -0.0174</td> <td>    0.023</td> <td>   -0.765</td> <td> 0.444</td> <td>   -0.062</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Symmetry_VG</th>          <td>   -0.0202</td> <td>    0.004</td> <td>   -5.391</td> <td> 0.000</td> <td>   -0.028</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Report_GIA</th>           <td>    0.0387</td> <td>    0.010</td> <td>    3.997</td> <td> 0.000</td> <td>    0.020</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Carat Weight:Color_E</th> <td>   -0.1077</td> <td>    0.017</td> <td>   -6.290</td> <td> 0.000</td> <td>   -0.141</td> <td>   -0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Carat Weight:Color_F</th> <td>   -0.1034</td> <td>    0.016</td> <td>   -6.389</td> <td> 0.000</td> <td>   -0.135</td> <td>   -0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Carat Weight:Color_G</th> <td>   -0.1535</td> <td>    0.015</td> <td>  -10.150</td> <td> 0.000</td> <td>   -0.183</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Carat Weight:Color_H</th> <td>   -0.2604</td> <td>    0.016</td> <td>  -16.612</td> <td> 0.000</td> <td>   -0.291</td> <td>   -0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Carat Weight:Color_I</th> <td>   -0.2926</td> <td>    0.016</td> <td>  -18.010</td> <td> 0.000</td> <td>   -0.324</td> <td>   -0.261</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>232.556</td> <th>  Durbin-Watson:     </th> <td>   2.007</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 808.024</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.055</td>  <th>  Prob(JB):          </th> <td>3.47e-176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.966</td>  <th>  Cond. No.          </th> <td>    166.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Price   R-squared:                       0.982\n",
       "Model:                            OLS   Adj. R-squared:                  0.982\n",
       "Method:                 Least Squares   F-statistic:                     9484.\n",
       "Date:                Mon, 11 Jan 2021   Prob (F-statistic):               0.00\n",
       "Time:                        13:15:31   Log-Likelihood:                 4623.5\n",
       "No. Observations:                5000   AIC:                            -9189.\n",
       "Df Residuals:                    4971   BIC:                            -9000.\n",
       "Df Model:                          28                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    9.3536      0.051    184.793      0.000       9.254       9.453\n",
       "Carat Weight             2.1472      0.013    171.045      0.000       2.123       2.172\n",
       "Cut_Good                 0.0490      0.010      4.817      0.000       0.029       0.069\n",
       "Cut_Ideal                0.1059      0.010     10.596      0.000       0.086       0.125\n",
       "Cut_Signature-Ideal      0.2494      0.012     20.227      0.000       0.225       0.274\n",
       "Cut_Very Good            0.0773      0.010      7.960      0.000       0.058       0.096\n",
       "Color_E                 -0.0667      0.006    -10.752      0.000      -0.079      -0.055\n",
       "Color_F                 -0.1097      0.006    -18.104      0.000      -0.122      -0.098\n",
       "Color_G                 -0.1963      0.006    -34.026      0.000      -0.208      -0.185\n",
       "Color_H                 -0.2953      0.006    -48.130      0.000      -0.307      -0.283\n",
       "Color_I                 -0.4314      0.006    -67.161      0.000      -0.444      -0.419\n",
       "Clarity_IF              -0.2296      0.049     -4.660      0.000      -0.326      -0.133\n",
       "Clarity_SI1             -0.7838      0.049    -16.023      0.000      -0.880      -0.688\n",
       "Clarity_VS1             -0.5443      0.049    -11.125      0.000      -0.640      -0.448\n",
       "Clarity_VS2             -0.6233      0.049    -12.741      0.000      -0.719      -0.527\n",
       "Clarity_VVS1            -0.3454      0.049     -7.022      0.000      -0.442      -0.249\n",
       "Clarity_VVS2            -0.4178      0.049     -8.529      0.000      -0.514      -0.322\n",
       "Polish_G                -0.0371      0.006     -6.608      0.000      -0.048      -0.026\n",
       "Polish_ID                0.0305      0.022      1.380      0.168      -0.013       0.074\n",
       "Polish_VG               -0.0225      0.004     -6.357      0.000      -0.029      -0.016\n",
       "Symmetry_G              -0.0242      0.005     -4.603      0.000      -0.035      -0.014\n",
       "Symmetry_ID             -0.0174      0.023     -0.765      0.444      -0.062       0.027\n",
       "Symmetry_VG             -0.0202      0.004     -5.391      0.000      -0.028      -0.013\n",
       "Report_GIA               0.0387      0.010      3.997      0.000       0.020       0.058\n",
       "Carat Weight:Color_E    -0.1077      0.017     -6.290      0.000      -0.141      -0.074\n",
       "Carat Weight:Color_F    -0.1034      0.016     -6.389      0.000      -0.135      -0.072\n",
       "Carat Weight:Color_G    -0.1535      0.015    -10.150      0.000      -0.183      -0.124\n",
       "Carat Weight:Color_H    -0.2604      0.016    -16.612      0.000      -0.291      -0.230\n",
       "Carat Weight:Color_I    -0.2926      0.016    -18.010      0.000      -0.324      -0.261\n",
       "==============================================================================\n",
       "Omnibus:                      232.556   Durbin-Watson:                   2.007\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              808.024\n",
       "Skew:                           0.055   Prob(JB):                    3.47e-176\n",
       "Kurtosis:                       4.966   Cond. No.                         166.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To conclude, and to understand the interactions better, lets explore the resultant model coefficients\n",
    "\n",
    "X_sm = sm.add_constant(X_train) \n",
    "lm = sm.OLS(Y_train, X_sm).fit() \n",
    "lm.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that interactions changed the model:\n",
    "\n",
    "Log of Price = 9.356 + 2.14 * Log of Carat Weight + ... - 0.0667 if Color=E ... - 0.1077 * Log of Price if Color=E ...\n",
    "\n",
    "That is, if Color=Е, the intercept changes from 9.356 to 9.356 - 0.0667, and the coefficient for the (log of) Carat Weight changes from 2.14 to 2.14 - 0.1077. In the previous model (without the interactions) if Color=Е, the intercept did change from 9.44 to 9.44 - 0.0858, but the coefficient for the Carat Weight remained at 1.987.\n",
    "\n",
    "In other words, because of interactions, the model could \"learn\" that how Price increases in Carat Weight depends on the Color of the diamond. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactions could also be implemented in sci-kit learn with the package PolynomialFeatures \n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures # load the package  \n",
    "\n",
    "poly = PolynomialFeatures(2) # define the object \"poly\" as a polynomial feature transofrmation of degree 2 (multiply all variables by all variables)\n",
    "\n",
    "# poly.fit_transform(XYZ) # apply poly to the matrix XYZ (substitute your data matrix instead of XYZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Use the trained model to predict the prices (or \"score\") the new diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000    16313.839238\n",
       "6001    44690.626719\n",
       "6002     3664.514017\n",
       "6003    22965.977867\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To finish the work on the case, lets use our last (best) model to predict the prices for IDs>=6001\n",
    "\n",
    "Sarah_data_prediction = Sarah_data[6000:] # Redfine the pridiction data so that it includes Logs and Interactions \n",
    "\n",
    "X_pred = Sarah_data_prediction.drop(['ID', 'Price'], axis = 1)\n",
    "\n",
    "X_pred = sm.add_constant(X_pred) \n",
    "\n",
    "Predictions = np.exp(lm.predict(X_pred)) \n",
    "\n",
    "Predictions[0:4] # Display first 4 predictions (note, in Python numbers start at 0, hence row \"6000\" is actually ID 6001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Export the model predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions.to_csv(\"Predicted Diamond Prices LOG INTERACTION.csv\",sep = ',') # export the predictions in to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hurray -- we finished the anlayses and obtained the predictions!\n",
    "\n",
    "How good are they? I computed their MAPE (recall, I know the actual prices for IDs 6001+) and the MAPE ~ 6.8% -- not bad at all after just one class. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Explaining banking products_v2_colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
